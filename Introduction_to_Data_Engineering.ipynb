{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3209559f-1c78-48b9-aa16-f4b0e1f80088",
   "metadata": {},
   "source": [
    "# What is Data Engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17c5c6-740a-4b3f-8c4b-9b0d2edbb62a",
   "metadata": {},
   "source": [
    "## Modern data ecosystem and role of data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffcf96-7188-448a-a0f2-bf8eeae1daef",
   "metadata": {},
   "source": [
    "### Summery"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffeb04ff-1762-469f-b4db-f9fc0f4137a7",
   "metadata": {},
   "source": [
    "Modern data ecosystem includes a network of interconnected and continually evolving entities that include:\n",
    "\n",
    "Data, that is available in a host of different formats, structures, and sources. \n",
    "\n",
    "Enterprise Data Environment, in which raw data is staged so it can be organized, cleaned, and optimized for use by end-users.\n",
    "\n",
    "End-users, such as business stakeholders, analysts, and programmers who consume data for various purposes.\n",
    "\n",
    "Emerging technologies such as Cloud Computing, Machine Learning, and Big Data, are continually reshaping the data ecosystem and the possibilities it offers.\n",
    "\n",
    "Data Engineers, Data Analysts, Data Scientists, Business Analysts, and Business Intelligence Analysts, all play a vital role in the ecosystem for deriving insights and business results from data.\n",
    "\n",
    "The goal of Data Engineering is to make quality data available for analytics and decision-making. And it does this by collecting raw source data, processing data so it becomes usable, storing data, and making quality data available to users securely.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40915b74-497a-43da-b22c-9b0e573efcd8",
   "metadata": {},
   "source": [
    "## Responsibilities and Skillsets of a Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d3c27-bb53-4821-98c5-cda6af870c00",
   "metadata": {},
   "source": [
    "### Technical skills"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09e2946a-d8d9-49ad-92a2-b3f9ef516020",
   "metadata": {},
   "source": [
    "Knowledge of working with operating systems such as UNIX, Linux, and Windows, including commonly used administrative tools, system utilities and commands.\n",
    "Knowledge of infrastructure components, such as virtual machines, networking, and application services, such as load balancing and application performance monitoring.\n",
    "Also, cloud-based services such as those offered by Amazon, Google, IBM, and Microsoft.\n",
    "Experience of working with databases and data warehouses, which include: RDBMSes such as IBM DB2, MySQL, Oracle Database, and PostgreSQL. NoSQL databases such as Redis, MongoDB, Cassandra, and Neo4J. Data warehouses such as Oracle Exadata, IBM Db2 Warehouse on Cloud, IBM Netezza Performance Server, and Amazon RedShift.\n",
    "A high-level of proficiency working with data pipelines. Popular data pipeline solutions include Apache Beam, AirFlow, and DataFLow.\n",
    "Experience of working with ETL tools such as IBM Infosphere Information Server, AWS Glue, and Improvado.\n",
    "Proficiency in languages for querying, manipulating, and processing data. This includes: Query languages for accessing and manipulating data in a database, such as SQL for relational databases and SQL-like query languages for NoSQL databases.\n",
    "Programming languages such as Python, R, and Java. Shell and Scripting languages, such as Unix/Linux Shell and PowerShell.\n",
    "Familiarity with Big Data processing tools such as Hadoop, Hive, and Spark.\n",
    "##\n",
    "Kafka is part of the data pipeline ecosystem, but it's not an ETL tool or orchestrator. It's best described as a real-time event streaming platform that enables pipelines, feeds ETL tools, and supports orchestration.\n",
    "##\n",
    "Kafka, Spark, Storm are applications for processing data streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6adf4c-55a0-4d3e-99e9-a5accb6db592",
   "metadata": {},
   "source": [
    "### Summery"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ebcc8c3-14ce-4cd5-a44f-2327b24f0c04",
   "metadata": {},
   "source": [
    "The role of a Data Engineer includes:\n",
    "\n",
    "Gathering data from disparate sources.\n",
    "\n",
    "Integrating data into a unified view for data consumers.\n",
    "\n",
    "Preparing data for analytics and reporting.\n",
    "\n",
    "Managing data pipelines for a continuous flow of data from source to destination systems.\n",
    "\n",
    "Managing the complete infrastructure for the collection, processing, and storage of data.\n",
    "\n",
    "To be successful in their role, Data Engineers need a mix of technical, functional, and soft skills.\n",
    "\n",
    "Technical Skills include working with different operating systems and infrastructure components such as virtual machines, networks, and application services. It also includes working with databases and data warehouses, data pipelines, ETL tools, big data processing tools, and languages for querying, manipulating, and processing data. \n",
    "\n",
    "An understanding of the potential application of data in business is an important skill for a data engineer. Other functional skills include the ability to convert business requirements into technical specifications, an understanding of the software development lifecycle, and the areas of data quality, privacy, security, and governance. \n",
    "\n",
    "Soft Skills include interpersonal skills, the ability to work collaboratively, teamwork, and effective communication. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbacbd7-3b7c-4427-9cbe-e550b2e9c0f1",
   "metadata": {},
   "source": [
    "## The Data Ecosystem and Languages for Data Professionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb0307-b777-478c-954a-e3f3c5e97b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
