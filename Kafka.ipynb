{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a46b63d-9cf1-4ff4-9f2a-dda5527343bf",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3f361c4-9a57-4ba0-adf0-5fac5ef7c127",
   "metadata": {},
   "source": [
    "a distributed event streaming platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827990cd-47fc-4f54-9c0b-b059c92b690d",
   "metadata": {},
   "source": [
    "# What is an Event in Kafka?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71c0ca25-10eb-4f36-8f0b-524ea4a3d905",
   "metadata": {},
   "source": [
    "An event is a record of something that happened, at a specific time, containing some data.\n",
    "\n",
    "It‚Äôs also often called a message, record, or log entry, depending on the use case or background of the person talking about it ‚Äî but in Kafka, \"event\" is the preferred term.\n",
    "\n",
    "Think of an event like a row in an append-only logbook that says:\n",
    "\n",
    "\"At this moment, something specific happened ‚Äî here's what it was and who it was about.\"\n",
    "An event in Kafka typically has three parts: Key-Value-Timestamp-Headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f438f-f52c-4000-b7f8-51bd1d24051c",
   "metadata": {},
   "source": [
    "# Key in a Kafka event"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfaedbff-b6d4-4fa6-a631-8a38ae3ad40c",
   "metadata": {},
   "source": [
    "Key as a Routing Identifier\n",
    "Think of it like this:\n",
    "\n",
    "Imagine you‚Äôre dropping letters into mailboxes.\n",
    "\n",
    "The key is like the recipient‚Äôs name.\n",
    "\n",
    "A topic in Kafka is like a category (e.g., user-activity).\n",
    "Each topic is divided into multiple partitions.\n",
    "Kafka distributes events across these partitions\n",
    "When you publish an event with a key, Kafka uses the key to consistently route all events with the same key to the same partition using a hashing algorithm.\n",
    "If you don‚Äôt provide a key, Kafka distributes events across partitions randomly\n",
    "\n",
    "In Summary\n",
    "üîë The Kafka Key is an optional part of an event that determines which partition the event goes to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf951d-69b7-4f3a-8c92-90ac37fbbf27",
   "metadata": {},
   "source": [
    "# Value in a Kafka Event"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b52e5a6-7b8b-40fc-88bf-95d38bbc9aba",
   "metadata": {},
   "source": [
    "The value is the main body or payload of the event.\n",
    "It contains the actual data that describes what happened.\n",
    "\n",
    "It's what your producer is sending, and what your consumer is reading and reacting to.\n",
    "You can think of the value as the body of an email:\n",
    "\n",
    "üßë‚Äçüíª Key ‚Üí Recipient name (to route to the right inbox = partition)\n",
    "\n",
    "üìÑ Value ‚Üí Message content (what you want them to read)\n",
    "\n",
    "What Kind of Data Can the Value Be?\n",
    "Kafka doesn‚Äôt care what your value is, as long as it's a byte array (under the hood). But in practice, it's usually serialized into one of the following formats: JSON, CSV, Plain text, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8bef2-970d-4403-ad68-5adca21fbe96",
   "metadata": {},
   "source": [
    "# Headers in a Kafka Event"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a23cf47-4877-464f-84c8-cae04281223f",
   "metadata": {},
   "source": [
    "Headers in Kafka are key‚Äìvalue pairs that you can attach to an event (alongside the key and value), but outside of the main payload (value).\n",
    "\n",
    "They're like metadata ‚Äî extra information about the event, not part of the core data.\n",
    "Key is a string (str)‚Äî can hold any kind of serialized data\n",
    "\n",
    "Value is a byte array (bytes) \n",
    "Serialized data refers to data that has been converted into a format that can be stored or transmitted and then reconstructed later. In simpler terms, serialization is like \"packing\" your data into a format that can be saved (e.g., to a file or sent over a network), and deserialization is the process of \"unpacking\" it back into its original structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182103f-3755-4b6d-a45a-865c713b522e",
   "metadata": {},
   "source": [
    "# Kafke client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fd75c0f-7f0f-480f-b5ea-0900f843539e",
   "metadata": {},
   "source": [
    "A Kafka client is a set of tools and code that lets your application interact with a Kafka cluster ‚Äî as a producer, consumer, or even admin.\n",
    "It‚Äôs like an API wrapper provided in various programming languages to abstract the Kafka protocol and let you send or read events easily from your code.\n",
    "for example in Python we have confluent-kafka or kafka-python\n",
    "Can You Use Kafka Without a Client Library?\n",
    "Technically, yes, but practically, it‚Äôs very complex and rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b2a636-a384-41a2-83a9-d8ce7cd40d5a",
   "metadata": {},
   "source": [
    "# Broker ‚Äì Producer ‚Äì Consumer - Admin"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4b17d89-72fa-4644-86a6-134bc711c772",
   "metadata": {},
   "source": [
    "Producer ‚Äî The Sender - Sends (publishes) events to Kafka\n",
    "A Producer is any application or service that creates and sends data (events) into a Kafka topic.\n",
    "For example:\n",
    "A FastAPI backend that logs user activities (login, signup, purchase) and sends them to Kafka.\n",
    "A sensor gateway that reports temperature every second.\n",
    "\n",
    "Broker ‚Äî The Kafka Server- Stores, manages, and serves the events\n",
    "A Broker is a single Kafka server that receives data from producers, stores it on disk, and serves it to consumers.\n",
    "Kafka is usually deployed as a cluster of brokers for high availability, fault tolerance, and horizontal scalability.\n",
    "üì¶ Think of the Broker as:\n",
    "A post office that receives letters (events) from senders (producers) and puts them into mailboxes (topics/partitions).\n",
    "Then, it hands those letters to readers (consumers) when they come asking.\n",
    "\n",
    "Consumer ‚Äî The Receiver - Reads (subscribes to) events from Kafka\n",
    "A Consumer is any application or service that reads and processes events from a Kafka topic.\n",
    "Example:\n",
    "A data pipeline that reads login events and stores them in PostgreSQL.\n",
    "A real-time fraud detection service that processes transactions.\n",
    "A batch job using Airflow that consumes yesterday‚Äôs data and writes summaries.\n",
    "\n",
    "The Admin is a Kafka client designed for cluster and topic management. It complements Producers, Consumers, and Brokers by allowing programmatic control over Kafka‚Äôs infrastructure, configurations, and metadata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
